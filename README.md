# Split Inference

In this project, the GPT-2 large model is divided into two parts: Upto embedding layers, it runs on phone and after that it runs on server/Laptop.

## GPT-2 Large

Vocab Size: 50257, Embedding Dim: 1280, Max Position Embeddings: 1024
Token embeddings saved with shape: (50257, 1280)
Position embeddings saved with shape: (1024, 1280)

# Client App

## Head model Architecture

Initially I tried using torch for head model but then I realized `torch` library is not available for android. So, to implement the head model (embedding layers), I used numpy.

1. Looking up token embeddings
2. Looking up positional embeddings
3. Adding these two embedding vectors.

- `save_embedding_weights.py`: This utility file saves the token and positional embedding layer weights as `.npy` files.
- `head_model_arch.py`: This class loads weight as `numpy` arrays and performs lookups using `numpy` indexing.

## Custom BPE Tokenizer

Using transformers library on client side was giving problem while running APK on phone. It was giving tqdm metadata file not found. That's why implementing a custom Byte Pair Encoding (BPE) tokenizer became a necessity.

- `save_tokenizer_files.py`: Download the required `vocab.json`, `merges.txt`, `special_tokens_map.json`, and `tokenizer_config.json` files.
- `custom_bpe_tokenizer.py`: This contains a Python implementation of the BPE algorithm that uses the GPT-2 tokenizer's specific vocabulary and merges rule. This is entirely generated by Gemini.

You can read more about this BPE tokenizer here [Sebastian Raschka](https://sebastianraschka.com/blog/2025/bpe-from-scratch.html).

# How to Run

Before running the program, you should first create a python virtual environment using:

``` bash
python -m venv my_venv
my_env\Scripts\activate    # activate the virtual environment
pip install -r requirements.txt  # Install the requirements
```

## Client

`flet build apk` - Use this command inside client_app folder to build APK for android

- When you try to build it for first time, it may take up to 25 minutes.
- After that when you build, it should not take more than 7 minutes

Other than APK, for testing you can run the client code using `python client.py`.

![alt text](image-1.png)

## Server

To start the server, use `python server.py` command.

![alt text](image.png)

# Tech Stack

- Python
- Flet library - python based app development. 
- Flutter - under the hood Flet uses flutter, hence flutter should be installed on your system.
- Web sockets - for bidirectional TCP based communication between the client and server.
- Torch
- Transformers